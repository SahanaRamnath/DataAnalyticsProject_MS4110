{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T08:07:12.824700Z",
     "start_time": "2018-11-11T08:07:12.815176Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T08:07:14.425512Z",
     "start_time": "2018-11-11T08:07:13.403727Z"
    }
   },
   "outputs": [],
   "source": [
    "mapping=pd.read_csv('comments_employee_mapping.csv').dropna()\n",
    "likes=pd.read_csv('comments_likeability.csv').dropna()\n",
    "attr=pd.read_csv('employee_attrition.csv').dropna()\n",
    "hap=pd.read_csv('happiness_level.csv').dropna()\n",
    "\n",
    "for d in [mapping,likes,attr,hap]:\n",
    "    d['id']=d['employee'].map(str)+d['companyAlias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T08:07:16.019183Z",
     "start_time": "2018-11-11T08:07:16.006409Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test=train_test_split(attr,stratify=attr.stillExists,test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T08:07:17.518645Z",
     "start_time": "2018-11-11T08:07:17.510002Z"
    }
   },
   "outputs": [],
   "source": [
    "train_id=X_train.id\n",
    "test_id=X_test.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T08:07:18.539093Z",
     "start_time": "2018-11-11T08:07:18.267942Z"
    }
   },
   "outputs": [],
   "source": [
    "mapping_train=mapping.loc[mapping.id.isin(train_id)]\n",
    "mapping_test=mapping.loc[mapping.id.isin(test_id)]\n",
    "attr_train=attr.loc[attr.id.isin(train_id)]\n",
    "attr_test=attr.loc[attr.id.isin(test_id)]\n",
    "likes_train=likes.loc[likes.id.isin(train_id)]\n",
    "likes_test=likes.loc[likes.id.isin(test_id)]\n",
    "hap_train=hap.loc[hap.id.isin(train_id)]\n",
    "hap_test=hap.loc[hap.id.isin(test_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T08:07:22.358503Z",
     "start_time": "2018-11-11T08:07:20.197268Z"
    }
   },
   "outputs": [],
   "source": [
    "hap_train.drop('id',axis=1).to_csv('happiness_level_train.csv')\n",
    "hap_test.drop('id',axis=1).to_csv('happiness_level_test.csv')\n",
    "likes_train.drop('id',axis=1).to_csv('comments_likeability_train.csv')\n",
    "likes_test.drop('id',axis=1).to_csv('comments_likeability_test.csv')\n",
    "attr_train.drop('id',axis=1).to_csv('employee_attrition_train.csv')\n",
    "attr_test.drop('id',axis=1).to_csv('employee_attrition_test.csv')\n",
    "mapping_train.drop('id',axis=1).to_csv('comments_employee_mapping_train.csv')\n",
    "mapping_test.drop('id',axis=1).to_csv('comments_employee_mapping_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T08:10:52.267658Z",
     "start_time": "2018-11-11T08:10:50.947592Z"
    }
   },
   "outputs": [],
   "source": [
    "mapping=pd.read_csv('comments_employee_mapping_train.csv').dropna()\n",
    "likes=pd.read_csv('comments_likeability_train.csv').dropna()\n",
    "attr=pd.read_csv('employee_attrition_train.csv').dropna()\n",
    "hap=pd.read_csv('happiness_level_train.csv').dropna()\n",
    "\n",
    "mapping_test=pd.read_csv('comments_employee_mapping_test.csv').dropna()\n",
    "likes_test=pd.read_csv('comments_likeability_test.csv').dropna()\n",
    "attr_test=pd.read_csv('employee_attrition_test.csv').dropna()\n",
    "hap_test=pd.read_csv('happiness_level_test.csv').dropna()\n",
    "\n",
    "for d in [mapping,likes,attr,hap,mapping_test,likes_test,attr_test,hap_test]:\n",
    "    d['id']=d['employee'].map(str)+d['companyAlias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T08:13:03.730375Z",
     "start_time": "2018-11-11T08:11:49.800134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "id_dict,comm_dict={},{}\n",
    "for i in range(len(likes)):\n",
    "    try: id_dict[likes['id'][i]]==0\n",
    "    except: id_dict[likes['id'][i]]=len(id_dict.keys())\n",
    "    try: comm_dict[likes['commentId'][i]]==0\n",
    "    except: comm_dict[likes['commentId'][i]]=len(comm_dict.keys())\n",
    "    if i%10000==0:print i\n",
    "m=np.zeros([len(id_dict.keys()),len(comm_dict.keys())])\n",
    "for i in range(len(likes)):\n",
    "    m[id_dict[likes['id'][i]],comm_dict[likes['commentId'][i]]]= likes['liked'][i]*1 - likes['disliked'][i]*1\n",
    "    if i%10000==0:print i\n",
    "    \n",
    "id_dict_c,comm_dict_c={},{}\n",
    "for i in range(len(mapping)):\n",
    "    try: id_dict_c[mapping['id'][i]]==0\n",
    "    except: id_dict_c[mapping['id'][i]]=len(id_dict_c.keys())\n",
    "    try: comm_dict_c[mapping['commentId'][i]]==0\n",
    "    except: comm_dict_c[mapping['commentId'][i]]=len(comm_dict_c.keys())\n",
    "    if i%10000==0:print i\n",
    "n=np.zeros([len(id_dict_c),len(comm_dict_c)])\n",
    "for i in range(len(mapping)):\n",
    "    n[id_dict_c[mapping['id'][i]],comm_dict_c[mapping['commentId'][i]]]=1\n",
    "    \n",
    "l=[]\n",
    "exc=0\n",
    "for i in range(len(attr)):\n",
    "    try:\n",
    "        l.append(m[id_dict[attr['id'][i]],:])\n",
    "    except:\n",
    "        exc+=1\n",
    "        l.append(np.zeros(len(comm_dict)))\n",
    "l=np.vstack(l)\n",
    "#np.save('likes_matrix_sparse_arranged.npy',[scipy.sparse.coo_matrix(l),comm_dict])\n",
    "\n",
    "\n",
    "c=[]\n",
    "exc_c=0\n",
    "for i in range(len(attr)):\n",
    "    try:\n",
    "        c.append(n[id_dict_c[attr['id'][i]],:])\n",
    "    except:\n",
    "        exc_c+=1\n",
    "        c.append(np.zeros(len(comm_dict_c)))\n",
    "c=np.vstack(c)\n",
    "#np.save('comment_matrix_sparse_arranged.npy',[scipy.sparse.coo_matrix(c),comm_dict_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T08:29:26.852119Z",
     "start_time": "2018-11-11T08:29:23.278055Z"
    }
   },
   "outputs": [],
   "source": [
    "id_dict_test={}\n",
    "for i in range(len(likes_test)):\n",
    "    try: id_dict_test[likes_test['id'][i]]==0\n",
    "    except: id_dict_test[likes_test['id'][i]]=len(id_dict_test)\n",
    "\n",
    "m_test=np.zeros([len(id_dict_test.keys()),len(comm_dict.keys())])\n",
    "for i in range(len(likes_test)):\n",
    "    try:m_test[id_dict_test[likes_test['id'][i]],comm_dict[likes_test['commentId'][i]]]= likes_test['liked'][i]*1 - likes_test['disliked'][i]*1\n",
    "    except:pass\n",
    "\n",
    "    \n",
    "id_dict_c_test={}\n",
    "for i in range(len(mapping_test)):\n",
    "    try: id_dict_c_test[mapping_test['id'][i]]==0\n",
    "    except: id_dict_c_test[mapping_test['id'][i]]=len(id_dict_c_test)\n",
    "\n",
    "n_test=np.zeros([len(id_dict_c_test),len(comm_dict_c)])\n",
    "for i in range(len(mapping_test)):\n",
    "    try:n_test[id_dict_c_test[mapping_test['id'][i]],comm_dict_c[mapping_test['commentId'][i]]]=1\n",
    "    except:pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T08:34:39.953553Z",
     "start_time": "2018-11-11T08:34:39.582908Z"
    }
   },
   "outputs": [],
   "source": [
    "l_test=[]\n",
    "for i in range(len(attr_test)):\n",
    "    try:l_test.append(m[id_dict_test[attr_test['id'][i]],:])\n",
    "    except:l_test.append(np.zeros(len(comm_dict)))\n",
    "l_test=np.vstack(l_test)\n",
    "\n",
    "c_test=[]\n",
    "for i in range(len(attr_test)):\n",
    "    try:c_test.append(n[id_dict_c_test[attr_test['id'][i]],:])\n",
    "    except:c_test.append(np.zeros(len(comm_dict_c)))\n",
    "c_test=np.vstack(c_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T08:35:02.130336Z",
     "start_time": "2018-11-11T08:35:02.119978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454, 36717)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
