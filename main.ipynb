{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict \n",
    "import time\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahana/anaconda3/lib/python3.6/site-packages/dateutil/parser/_parser.py:1204: UnknownTimezoneWarning: tzname CET identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n",
      "/home/sahana/anaconda3/lib/python3.6/site-packages/dateutil/parser/_parser.py:1204: UnknownTimezoneWarning: tzname CEST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n"
     ]
    }
   ],
   "source": [
    "loc = './'\n",
    "mapping=pd.read_csv(loc + 'comments_employee_mapping.csv').dropna()\n",
    "likes=pd.read_csv(loc + 'comments_likeability.csv').dropna()\n",
    "attr=pd.read_csv(loc + 'employee_attrition.csv').dropna()\n",
    "hap=pd.read_csv(loc + 'happiness_level.csv').dropna()\n",
    "\n",
    "attr['lastParticipationDate']=pd.to_datetime(attr['lastParticipationDate'],infer_datetime_format=True)\n",
    "mapping['commentDate']=pd.to_datetime(mapping['commentDate'],infer_datetime_format=True)\n",
    "hap['voteDate']=pd.to_datetime(hap['voteDate'],infer_datetime_format=True)\n",
    "\n",
    "for d in [mapping,likes,attr,hap]:\n",
    "    d['id']=d['employee'].map(str) + d['companyAlias']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping employee and comment id to range of integers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4377 4377\n",
      "38993 38993\n"
     ]
    }
   ],
   "source": [
    "employee_ids = np.unique(attr['id'].values)\n",
    "comment_ids = np.unique(mapping['commentId'].values)\n",
    "\n",
    "init = np.arange(1, len(employee_ids) + 1)\n",
    "map_employee = OrderedDict(list(zip(employee_ids, init)))\n",
    "init = np.arange(1, len(comment_ids) + 1)\n",
    "map_comment = OrderedDict(list(zip(comment_ids, init)))\n",
    "    \n",
    "print(len(map_employee), len(np.unique(employee_ids)))\n",
    "print(len(map_comment), len(np.unique(comment_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding goodness scores of the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 307_56aec740f1ef260003e307d6\n",
      "1000 91_56aec740f1ef260003e307d6\n",
      "2000 432_56aec740f1ef260003e307d6\n",
      "3000 271_56aec740f1ef260003e307d6\n",
      "4000 16_56aec740f1ef260003e307d6\n",
      "5000 90_56aec740f1ef260003e307d6\n",
      "6000 39_5370af43e4b0cff95558c12a\n",
      "7000 125_57bb2f0b3bae540003a8d453\n",
      "8000 62_567011c035dce00003a07fa4\n",
      "9000 31_5809cc9eff2ea40003fda44d\n",
      "10000 129_581b08041a0ef8000308aef6\n",
      "11000 15_574c423856b6300003009953\n",
      "12000 38_57908a2622881200033b34d7\n",
      "13000 219_54e52607e4b01191dc064966\n",
      "14000 996_54e52607e4b01191dc064966\n",
      "15000 709_54e52607e4b01191dc064966\n",
      "16000 267_54e52607e4b01191dc064966\n",
      "17000 80_54e52607e4b01191dc064966\n",
      "18000 165_54e52607e4b01191dc064966\n",
      "19000 139_57dd2d6a4018d9000339ca43\n",
      "20000 99_57dd2d6a4018d9000339ca43\n",
      "21000 162_5641f96713664c000332c8cd\n",
      "22000 146_5641f96713664c000332c8cd\n",
      "23000 425_5641f96713664c000332c8cd\n",
      "24000 6_57c4aa7dbb8b5c000396fd3b\n",
      "25000 4_56e2a905e3b6fe0003e32855\n",
      "26000 6_56e2a905e3b6fe0003e32855\n",
      "27000 380_574c5ade56b6300003009965\n",
      "28000 341_574c5ade56b6300003009965\n",
      "29000 99_574c5ade56b6300003009965\n",
      "30000 151_53a2dd43e4b01cc02f1e9011\n",
      "31000 111_53a2dd43e4b01cc02f1e9011\n",
      "32000 53_57ac8b23be7fe30003e656d0\n",
      "33000 32_57ac8b23be7fe30003e656d0\n",
      "34000 213_5742d699f839a10003a407d2\n",
      "35000 181_5742d699f839a10003a407d2\n",
      "36000 16_57d956302a040a00036a8905\n",
      "37000 173_57d956302a040a00036a8905\n",
      "38000 38_58a728a0e75bda00042a3468\n",
      "1453.468762397766\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "list_of_unique_comments=list(map_comment)\n",
    "goodness_score={}\n",
    "for i in range(len(list_of_unique_comments)) : \n",
    "    comment_id=list_of_unique_comments[i]\n",
    "    employee_who_made=mapping[mapping['commentId']==comment_id]['id']\n",
    "    employee_who_made=list(employee_who_made)[0]\n",
    "    \n",
    "    current_goodness_score=0\n",
    "    # assuming employee who made the comment likes it\n",
    "    if list(attr[attr['id']==employee_who_made]['stillExists'])[-1] : \n",
    "        current_goodness_score+=1\n",
    "    else : \n",
    "        current_goodness_score-=1\n",
    "\n",
    "    like_dislike=likes[likes['commentId']==comment_id][['id','liked','disliked']]\n",
    "    \n",
    "    \n",
    "    for j,like,dislike in zip(like_dislike['id'],like_dislike['liked'],like_dislike['disliked']) : \n",
    "        j_stayed=list(attr[attr['id']==j]['stillExists'])[-1]\n",
    "        if j_stayed and like : \n",
    "            current_goodness_score+=1\n",
    "        if j_stayed and dislike : \n",
    "            current_goodness_score-=1\n",
    "        if (not j_stayed) and like : \n",
    "            current_goodness_score-=1\n",
    "        if (not j_stayed) and dislike : \n",
    "            current_goodness_score+=1\n",
    "    #print(current_goodness_score,float(len(like_dislike['id'])))\n",
    "    current_goodness_score=current_goodness_score/float(len(like_dislike['id'])+1)\n",
    "    goodness_score[comment_id]=current_goodness_score    \n",
    "    if i%1000==0 : \n",
    "        print(i,employee_who_made)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('comment_goodness_scores',goodness_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.load('comment_goodness_scores.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c==goodness_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building employee - comment reaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.zeros([len(employee_ids),len(comment_ids)])\n",
    "\n",
    "for i in range(len(employee_ids)):\n",
    "    emp_idx = map_employee[likes['id'][i]]\n",
    "    com_idx = map_comment[likes['commentId'][i]]\n",
    "    if likes['liked'][i]==True:\n",
    "        d[emp_idx, com_idx] = 1\n",
    "    else:\n",
    "        d[emp_idx, com_idx] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3226\n",
      "-1.0\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(map_employee['51756aec740f1ef260003e307d6'])\n",
    "print(d[map_employee['2456aec740f1ef260003e307d6'], map_comment['58d0179ae010990004e3806d']])\n",
    "\n",
    "print(d[map_employee['15256aec740f1ef260003e307d6'], map_comment['58cfefeee010990004e37f60']])\n",
    "print(d[map_employee['3456aec740f1ef260003e307d6'], map_comment['58d018d7e010990004e38070']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Columns for Liking/Disliking Comments Based on Goodness Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscore = np.load('comment_goodness_scores.npy').item()\n",
    "gscore = pd.DataFrame({'commentId': gscore.keys(), 'score': gscore.values()})\n",
    "gscore.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Takes a lot of time to run!\n",
    "comment_reac = []\n",
    "iternum = 0\n",
    "for emp in np.unique(attr['id']):\n",
    "    if iternum%100==0: print iternum\n",
    "    iternum += 1\n",
    "    emp_reac = pd.DataFrame(data = [[emp, 0, 0, 0, 0]], columns=['id', 'good_like', 'good_dislike', 'bad_like', 'bad_dislike'])\n",
    "    for _, like in likes[likes.id==emp].iterrows():\n",
    "        try: score = gscore[gscore.commentId == like.commentId].score.values[0]\n",
    "        except: score = 0\n",
    "        if score > 0:             # Good comment\n",
    "            if like.liked==True:  # Like \n",
    "                emp_reac['good_like'] += score \n",
    "            else:                 # Dislike\n",
    "                emp_reac['good_dislike'] -= score                 \n",
    "        else:                     # Bad comment\n",
    "            if like.liked==True:   # Like  \n",
    "                emp_reac['bad_like'] += score \n",
    "            else:                 # Dislike\n",
    "                emp_reac['bad_dislike'] -= score \n",
    "    comment_reac.append(emp_reac)\n",
    "comment_reac = pd.concat(comment_reac, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_reac.to_pickle('./goodness_classified_matrix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usage: \n",
    "# pd.read_pickle('./goodness_classified_matrix.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
